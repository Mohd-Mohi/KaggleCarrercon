{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\Mohiuddin\\Desktop\\machine learning\\ML\\incedo-hackerearth\\incedo_participant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_dataset.csv\")\n",
    "test = pd.read_csv(\"test_dataset.csv\")\n",
    "sub = pd.read_csv(\"test_dataset.csv\")\n",
    "submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Essayset</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>EssayText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>Some additional information that we would need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>excellent</td>\n",
       "      <td>worst</td>\n",
       "      <td>After reading the expirement, I realized that ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Essayset  min_score  max_score  score_1  score_2  score_3  score_4  \\\n",
       "0   1       1.0          0          3        1        1      1.0      1.0   \n",
       "1   2       1.0          0          3        1        1      NaN      1.5   \n",
       "\n",
       "   score_5    clarity coherent  \\\n",
       "0      1.0    average    worst   \n",
       "1      1.0  excellent    worst   \n",
       "\n",
       "                                           EssayText  \n",
       "0  Some additional information that we would need...  \n",
       "1  After reading the expirement, I realized that ...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Essayset</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>EssayText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>The procedures I think they should have includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1674</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>In order to replicate this experiment, you wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>above_average</td>\n",
       "      <td>above_average</td>\n",
       "      <td>In order to replicate their experiment, you wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1676</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>worst</td>\n",
       "      <td>worst</td>\n",
       "      <td>Pleace a simple of one material into one conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1677</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>worst</td>\n",
       "      <td>worst</td>\n",
       "      <td>Determin the mass of four different samples ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Essayset  min_score  max_score        clarity       coherent  \\\n",
       "0  1673         1          0          3        average          worst   \n",
       "1  1674         1          0          3        average          worst   \n",
       "2  1675         1          0          3  above_average  above_average   \n",
       "3  1676         1          0          3          worst          worst   \n",
       "4  1677         1          0          3          worst          worst   \n",
       "\n",
       "                                           EssayText  \n",
       "0  The procedures I think they should have includ...  \n",
       "1  In order to replicate this experiment, you wou...  \n",
       "2  In order to replicate their experiment, you wo...  \n",
       "3  Pleace a simple of one material into one conta...  \n",
       "4  Determin the mass of four different samples ma...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1674</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1676</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1677</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  essay_set  essay_score\n",
       "0  1673          1          NaN\n",
       "1  1674          1          NaN\n",
       "2  1675          1          NaN\n",
       "3  1676          1          NaN\n",
       "4  1677          1          NaN"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_score = train[[\"score_1\",\"score_2\",\"score_3\",\"score_4\",\"score_5\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['essay_score'] = essay_score.mean(axis=1).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Essayset</th>\n",
       "      <th>min_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>score_1</th>\n",
       "      <th>score_2</th>\n",
       "      <th>score_3</th>\n",
       "      <th>score_4</th>\n",
       "      <th>score_5</th>\n",
       "      <th>clarity</th>\n",
       "      <th>coherent</th>\n",
       "      <th>EssayText</th>\n",
       "      <th>essay_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>average</td>\n",
       "      <td>worst</td>\n",
       "      <td>Some additional information that we would need...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>excellent</td>\n",
       "      <td>worst</td>\n",
       "      <td>After reading the expirement, I realized that ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>worst</td>\n",
       "      <td>above_average</td>\n",
       "      <td>What you need is more trials, a control set up...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>worst</td>\n",
       "      <td>worst</td>\n",
       "      <td>The student should list what rock is better an...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>above_average</td>\n",
       "      <td>worst</td>\n",
       "      <td>For the students to be able to make a replicat...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Essayset  min_score  max_score  score_1  score_2  score_3  score_4  \\\n",
       "0   1       1.0          0          3        1        1      1.0      1.0   \n",
       "1   2       1.0          0          3        1        1      NaN      1.5   \n",
       "2   3       1.0          0          3        1        1      1.0      1.0   \n",
       "3   4       1.0          0          3        0        0      0.0      0.0   \n",
       "4   5       1.0          0          3        2        2      2.0      2.5   \n",
       "\n",
       "   score_5        clarity       coherent  \\\n",
       "0      1.0        average          worst   \n",
       "1      1.0      excellent          worst   \n",
       "2      1.5          worst  above_average   \n",
       "3      1.0          worst          worst   \n",
       "4      1.0  above_average          worst   \n",
       "\n",
       "                                           EssayText  essay_score  \n",
       "0  Some additional information that we would need...          1.0  \n",
       "1  After reading the expirement, I realized that ...          1.0  \n",
       "2  What you need is more trials, a control set up...          1.0  \n",
       "3  The student should list what rock is better an...          0.0  \n",
       "4  For the students to be able to make a replicat...          2.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([\"score_1\",\"score_2\",\"score_3\",\"score_4\",\"score_5\"],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17043, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID               0\n",
       "Essayset       157\n",
       "min_score        0\n",
       "max_score        0\n",
       "clarity        138\n",
       "coherent       145\n",
       "EssayText        0\n",
       "essay_score      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'average':1, 'excellent':2, 'worst':3, 'above_average':4,np.nan : train.clarity.mode()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"clarity\"] = train.clarity.map(mapping) \n",
    "test[\"clarity\"] = test.clarity.map(mapping) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['worst', 'above_average', 'average', 'excellent', nan],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.coherent.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'worst':3, 'above_average':4, 'average':1, 'excellent':2,np.nan : train.coherent.mode()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"coherent\"] = train.coherent.map(mapping) \n",
    "test[\"coherent\"] = test.coherent.map(mapping) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID               0\n",
       "Essayset       157\n",
       "min_score        0\n",
       "max_score        0\n",
       "clarity          0\n",
       "coherent         0\n",
       "EssayText        0\n",
       "essay_score      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID             0\n",
       "Essayset       0\n",
       "min_score      0\n",
       "max_score      0\n",
       "clarity        0\n",
       "coherent       0\n",
       "EssayText      0\n",
       "essay_score    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x186d741f860>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x185e98d0208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.essay_score.value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.essay_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([\"ID\",\"essay_score\"],axis = 1,inplace = True)\n",
    "test.drop(\"ID\",axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17043, 6)\n",
      "(5224, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17043, 15921)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit and transform X_train into X_train_dtm\n",
    "X_train_dtm = vect.fit_transform(train[\"EssayText\"])\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test[\"EssayText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5224, 15921)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit and transform X_train into X_train_dtm\n",
    "X_test_dtm = vect.transform(test1)\n",
    "X_test_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "def tfidf(data):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    train = tfidf_vectorizer.fit_transform(data)\n",
    "\n",
    "    return train, tfidf_vectorizer\n",
    "\n",
    "X_train_tfidf, tfidf_vectorizer = tfidf(train[\"EssayText\"])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test[\"EssayText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pp = pd.DataFrame(X_atrain_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "nb.fit(X_train_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = nb.predict(X_test_tfidf)\n",
    "final_result = pd.DataFrame({'id':sub['ID'],'essay_set':sub['Essayset'],'essay_score':predictions})\n",
    "xy  = final_result[[\"id\",\"essay_set\",\"essay_score\"]]\n",
    "xy.to_csv('NBSolution.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=700, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=700)\n",
    "model.fit(X_train_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_tfidf)\n",
    "final_result = pd.DataFrame({'id':sub['ID'],'essay_set':sub['Essayset'],'essay_score':predictions})\n",
    "xy  = final_result[[\"id\",\"essay_set\",\"essay_score\"]]\n",
    "xy.to_csv('RFSolution2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_tfidf, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logreg.predict(X_test_tfidf)\n",
    "final_result = pd.DataFrame({'id':sub['ID'],'essay_set':sub['Essayset'],'essay_score':predictions})\n",
    "xy  = final_result[[\"id\",\"essay_set\",\"essay_score\"]]\n",
    "xy.to_csv('lg1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf svd features\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=1200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(X_train_tfidf, y)\n",
    "predictions = clf.predict(X_test_tfidf)\n",
    "\n",
    "#print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = pd.DataFrame({'id':sub['ID'],'essay_set':sub['Essayset'],'essay_score':predictions})\n",
    "xy  = final_result[[\"id\",\"essay_set\",\"essay_score\"]]\n",
    "xy.to_csv('xgbSolution9.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
